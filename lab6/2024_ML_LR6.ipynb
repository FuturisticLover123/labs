{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "c0688b91",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from scipy.stats import entropy"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "628dc6a1-ade7-49e0-a6b3-5ebb2cfbe60a",
   "metadata": {},
   "source": [
    "# <font color = 'red'> ЛР 6. Дерево решений. Метрики f1 качества классификации. </font>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1b98c829-7c67-4ac5-87e1-b50c6d6bd510",
   "metadata": {},
   "source": [
    "Сложность: <font color = 'green'> Легко  </font>.\n",
    "\n",
    "Дата составления: 07.10.2024\n",
    "\n",
    "Срок выполнения: 2 недели (с момента первой практики после выдачи).\n",
    "\n",
    "Автор: ст. преподаватель Кушнеров А.В."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b61b8275",
   "metadata": {},
   "source": [
    "## <font color = 'green'> 1. Энтропия.  </font>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1745e687",
   "metadata": {},
   "source": [
    "**Энтропия Шеннона** - мера хаотичности множества. Пусть задано множество из $N$ представителей $s$ различных классов. $X = (x_{1},x_{1},x_{1},...,x_{2},x_{2},...,...x_{s},x_{s},...)$.\n",
    "\n",
    "Энтропия тогда может быть вычислена по формуле:\n",
    "\n",
    "$$S(X)=-\\displaystyle\\sum_{i=1}^{s} p_{i}\\log_2 p_{i}$$\n",
    "\n",
    "Где, $p_{i}=N_{i}/N$."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4de55f55",
   "metadata": {},
   "source": [
    "<font color = 'red' size = 5>Задание 1 </font>\n",
    "\n",
    "Реализуйте функцию для подсчёта энтропии Шеннонна для заданной выборки. Сравните результат работы со встроенной функцией.\n",
    "\n",
    "\n",
    "[Справочная информация](https://ru.wikipedia.org/wiki/%D0%98%D0%BD%D1%84%D0%BE%D1%80%D0%BC%D0%B0%D1%86%D0%B8%D0%BE%D0%BD%D0%BD%D0%B0%D1%8F_%D1%8D%D0%BD%D1%82%D1%80%D0%BE%D0%BF%D0%B8%D1%8F)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "e92121a9",
   "metadata": {},
   "outputs": [],
   "source": [
    "test = np.random.randint(0,3,100)\n",
    "test\n",
    "\n",
    "unique, counts = np.unique(test, return_counts=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "3188b011",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1.576179186690877"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "entropy(counts,base=2)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a56618ad",
   "metadata": {},
   "source": [
    "## <font color = 'green'> 2. Прирост информации и дерево принятия решений  </font>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c5b8a97e",
   "metadata": {},
   "source": [
    "Пусть исходное множество $X$ было разделено на несколько подмножеств (чаще всего на 2). В каждом из них можем посчитать энтропию. Мы ожидаем, что наше разбиение уменьшит энтропию в каждом из подмножеств или в целом, что должно приблизить нас к решению задачи классификации. Для того, чтобы получить полную картину вводят понятие прироста информации.\n",
    "\n",
    "$$IG(Q) = S_{0}-\\displaystyle\\sum_{i=1}^{q} \\frac{N_{i}}{N}S_{i}$$\n",
    "\n",
    "Тут имеем: $S_{0}$ - энтропия исходного множества, $N_{i}$ - количесвто элементов в каждом новом классе после разбиения, $N$ - исходное количество элементов, $q$ - количество множеств после разбиения,  $S_{i}$ - энтропия новых множеств.\n",
    "\n",
    "\n",
    "Суть работы решающего дерева в разделении обучающего множества на подмножества, так чтобы энтропия выборки меток уменьшалась по каждому подмножеству, а прирост информации увеличивался. В качестве критерия для разделения(по признакам) выбирают тот, который даёт наибольший прирост информации (по меткам). Эта процедура повторяется рекурсивно.\n",
    "\n",
    "[Справочная информация](https://scikit-learn.org/stable/modules/tree.html#tree)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c8cff8e3",
   "metadata": {},
   "source": [
    "<font color = 'red' size = 5>Задание 2 </font>\n",
    "\n",
    "\n",
    "1. Реализуйте учебное приложение, которое строит решающее дерево на основе энтропии классификации на данных состоящих не более чем из двух признаков.\n",
    "2. Проверьте своё приложение на простых искусственных данных и сравните со встроенным классом DecisionTreeClassifier.\n",
    "3. Реализуйте учебное приложение, которое строит решающее дерево на основе критерия Джини классификации на данных состоящих не более чем из двух признаков.*"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f7a649cc",
   "metadata": {},
   "source": [
    "<font color = 'red' size = 5>Задание 3 </font>\n",
    "\n",
    "Для каждого из подзаданий:\n",
    "\n",
    "1. Проведите предварительную обработку данных.\n",
    "2. Постройте модель классификации на основе метода решающего дерева из встроенной библиотеки. \n",
    "3. Подберите оптимальные гиперпараметры модели используя различные оценки, кросс-валидацию и валидационные кривые.\n",
    "4. Сделайте выводы о точности моделей.\n",
    "5. Продумайте, как дерево может бороться с переобучением. Подвердите валидационными кривыми. \n",
    "6. Оцените качество модели с помощью precision\\recall score.\n",
    "\n",
    "(https://scikit-learn.org/stable/auto_examples/model_selection/plot_precision_recall.html)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "53471a68",
   "metadata": {},
   "source": [
    "##### 3.1 Самый известный датасет в мире.\n",
    "\n",
    "Используйте данные из сэта о [титанике](https://www.kaggle.com/c/titanic) для предсказания выживания. \n",
    "Предврительно изучите и подготовьте данные.\n",
    "\n",
    "#####  3.2 Предсказание диабета у пациентов.\n",
    "\n",
    "Используйте данные из файла [diabetes.csv](https://www.kaggle.com/datasets/saurabh00007/diabetescsv) для предсказания исхода для пациентов. Столбец \"outcome\". Предварительно изучите и подготовьте данные. \n",
    "\n",
    "\n",
    "##### 3.3 Данные о цветках ириса\n",
    "\n",
    "[IrisDataset](https://www.kaggle.com/datasets/uciml/iris)\n",
    "\n",
    "##### 3.4 Грибы\n",
    "\n",
    "Поппробуйте предсказать съедобность гриба с помощью дерева принятия решений.\n",
    "[mushrooms](https://www.kaggle.com/datasets/uciml/mushroom-classification/code)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a14b51cd",
   "metadata": {},
   "source": [
    "<font color = 'red' size = 5>Задание 4 </font>\n",
    "\n",
    "Используя встроенные методы реализуйте регрессию с помощью решающего дерева. Примените для данных из предыдущих ЛР. Сделайте выводы. По какому принципу работает дерево в случае регресии?"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
